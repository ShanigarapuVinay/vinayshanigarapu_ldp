{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a283ff86-e2d8-4e39-b5d5-2396ede06cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660de48d-104c-4d39-8d4a-f52c02d9fe7e",
   "metadata": {},
   "source": [
    "## Prepare the document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ed29ba-c8de-4d32-856d-15eb0fa62492",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Python is a high-level programming language known for its simplicity and readability.\",\n",
    "    \"Machine learning is a subset of artificial intelligence that focuses on data and algorithms.\",\n",
    "    \"Natural Language Processing (NLP) enables computers to understand human language.\",\n",
    "    \"Deep learning models can automatically learn representations from data.\",\n",
    "    \"Vector databases are specialized databases for storing and retrieving vector embeddings.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68288453-b392-4977-86bb-53f8d2cf3345",
   "metadata": {},
   "source": [
    "## Generate embeddings for the document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d970ae63-7c31-4c8e-9cdb-7a36247255d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for documents...\n"
     ]
    }
   ],
   "source": [
    "def generate_embeddings(texts):\n",
    "    response = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return [embedding['embedding'] for embedding in response['data']]\n",
    "\n",
    "print(\"Generating embeddings for documents...\")\n",
    "document_embeddings = generate_embeddings(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fd2f7-0546-4bef-91ec-20a8a80513bc",
   "metadata": {},
   "source": [
    "## Store embeddings in FAISS vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8b16bb-9f00-4680-8e75-c3cd811143f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created with 5 documents\n"
     ]
    }
   ],
   "source": [
    "dimension = len(document_embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "document_embeddings_array = np.array(document_embeddings).astype('float32')\n",
    "index.add(document_embeddings_array)\n",
    "print(f\"Vector database created with {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f7340-f03d-4a8c-bb87-513dd60798b0",
   "metadata": {},
   "source": [
    "## Function to retrieve relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4214cb61-de50-4be5-bb0e-b42f60dba585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(query, k=2):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = generate_embeddings([query])[0]\n",
    "    query_array = np.array([query_embedding]).astype('float32')\n",
    "    \n",
    "    # Search in vector database\n",
    "    distances, indices = index.search(query_array, k)\n",
    "    \n",
    "    # Get relevant documents\n",
    "    relevant_docs = [documents[i] for i in indices[0]]\n",
    "    return relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c051e-ef6b-4705-9d80-c8c21881560f",
   "metadata": {},
   "source": [
    "##  Function to generate chatbot response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ecc70d-9c58-457f-88f0-5f62f779e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query):\n",
    "    # Get relevant documents\n",
    "    relevant_context = get_relevant_context(query)\n",
    "    \n",
    "    # Prepare prompt with context\n",
    "    prompt = f\"\"\"Use the following context to answer the question. \n",
    "    If the context doesn't contain relevant information, say so.\n",
    "    \n",
    "    Context: {' '.join(relevant_context)}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    # Generate response using ChatGPT\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'answer': response.choices[0].message['content'],\n",
    "        'relevant_documents': relevant_context\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84e275-0927-4dbb-843e-4ce39debc74f",
   "metadata": {},
   "source": [
    "## Interactive chatbot interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815f1f9c-0f84-4689-9099-25893c1ba0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot initialized. Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  What is Python?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot: Python is a high-level programming language known for its simplicity and readability.\n",
      "\n",
      "Relevant documents used:\n",
      "- Python is a high-level programming language known for its simplicity and readability.\n",
      "- Natural Language Processing (NLP) enables computers to understand human language.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Tell me about Naruto Anime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot: The provided context does not contain relevant information about the Naruto Anime.\n",
      "\n",
      "Relevant documents used:\n",
      "- Natural Language Processing (NLP) enables computers to understand human language.\n",
      "- Python is a high-level programming language known for its simplicity and readability.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Chatbot initialized. Type 'quit' to exit.\")\n",
    "    while True:\n",
    "        query = input(\"\\nYou: \").strip()\n",
    "        if query.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        result = generate_response(query)\n",
    "        print(\"\\nChatbot:\", result['answer'])\n",
    "        print(\"\\nRelevant documents used:\")\n",
    "        for doc in result['relevant_documents']:\n",
    "            print(f\"- {doc}\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18805b98-4485-4e2a-8291-cba3640fc613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
